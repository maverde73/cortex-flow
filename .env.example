# LLM API Keys
OPENAI_API_KEY=""
ANTHROPIC_API_KEY=""
GOOGLE_API_KEY=""
GROQ_API_KEY=""
OPENROUTER_API_KEY=""

# LangSmith Configuration (Optional - for observability)
LANGSMITH_API_KEY=""
LANGSMITH_PROJECT="cortex-flow"
LANGSMITH_TRACING=false

# Server Configuration
SUPERVISOR_HOST=localhost
SUPERVISOR_PORT=8000
RESEARCHER_HOST=localhost
RESEARCHER_PORT=8001
REDDIT_HOST=localhost
REDDIT_PORT=8002
ANALYST_HOST=localhost
ANALYST_PORT=8003
WRITER_HOST=localhost
WRITER_PORT=8004

# HTTP Client Configuration
HTTP_TIMEOUT=120.0
HTTP_MAX_CONNECTIONS=100
HTTP_MAX_KEEPALIVE_CONNECTIONS=20

# State Management
# Options: "memory" (dev only), "postgres", "redis"
CHECKPOINT_BACKEND=memory
POSTGRES_URL=""
REDIS_URL=""

# ============================================================================
# LLM CONFIGURATION
# ============================================================================

# Default Model (used when no agent-specific model is configured)
# Format: provider/model
# Examples:
#   openai/gpt-4o-mini
#   anthropic/claude-sonnet-4-20250514
#   google/gemini-1.5-flash
#   openrouter/anthropic/claude-3.5-sonnet
DEFAULT_MODEL=openai/gpt-4o-mini

# Per-Agent Models (Optional - override DEFAULT_MODEL for specific agents)
# Uncomment and configure to use different models for different agents
#RESEARCHER_MODEL=anthropic/claude-sonnet-4-20250514
#ANALYST_MODEL=openai/gpt-4o
#WRITER_MODEL=anthropic/claude-opus-4-20250514
#SUPERVISOR_MODEL=openai/gpt-4o-mini

# Task-Specific Models (Optional - use different models for specific tasks within an agent)
# Examples:
#   Deep research tasks might need a more powerful model
#   Quick searches can use a faster, cheaper model
#RESEARCHER_DEEP_ANALYSIS_MODEL=anthropic/claude-opus-4-20250514
#RESEARCHER_QUICK_SEARCH_MODEL=openai/gpt-4o-mini
#WRITER_CREATIVE_MODEL=anthropic/claude-opus-4-20250514
#WRITER_TECHNICAL_MODEL=openai/gpt-4o
#ANALYST_CODE_REVIEW_MODEL=openai/o1

# Provider Fallback Order
# If a configured model is unavailable, try providers in this order
# Comma-separated list of: openai, anthropic, google, groq, openrouter
PROVIDER_FALLBACK_ORDER=openai,anthropic,google,groq,openrouter

# LLM Parameters
TEMPERATURE=0.7
MAX_ITERATIONS=10

# ============================================================================
# REACT PATTERN CONFIGURATION (FASE 1 - Fondamenti)
# ============================================================================

# ReAct timeout in seconds - maximum time allowed for agent execution
REACT_TIMEOUT_SECONDS=120.0

# Enable early stopping mechanism for safety
REACT_ENABLE_EARLY_STOPPING=true

# Maximum consecutive errors before aborting (prevents infinite error loops)
REACT_MAX_CONSECUTIVE_ERRORS=3

# Verbose logging - enables detailed console output for debugging
REACT_ENABLE_VERBOSE_LOGGING=true

# Log individual ReAct components (Thought/Action/Observation)
REACT_LOG_THOUGHTS=true
REACT_LOG_ACTIONS=true
REACT_LOG_OBSERVATIONS=true

# ============================================================================
# REACT REASONING STRATEGIES (FASE 2)
# ============================================================================

# Per-Agent Reasoning Strategies
# Defines how each agent approaches reasoning tasks
# Options: fast, balanced, deep, creative
#
# FAST (quick responses, 3 iterations, 30s timeout, temp 0.3):
#   - Use for: Simple queries, routing, quick decisions
#   - Example: Supervisor coordination
#
# BALANCED (moderate depth, 10 iterations, 120s timeout, temp 0.7):
#   - Use for: Standard analysis, general queries
#   - Example: Analyst processing
#
# DEEP (thorough research, 20 iterations, 300s timeout, temp 0.7):
#   - Use for: Complex research, comprehensive analysis
#   - Example: Researcher web searches
#
# CREATIVE (exploratory, 15 iterations, 180s timeout, temp 0.9):
#   - Use for: Content generation, brainstorming
#   - Example: Writer content creation

SUPERVISOR_REACT_STRATEGY=fast
RESEARCHER_REACT_STRATEGY=deep
ANALYST_REACT_STRATEGY=balanced
WRITER_REACT_STRATEGY=creative

# Task-Specific Strategy Overrides (Optional)
# Override agent strategy for specific task types
# Format: {AGENT}_{TASK}_REACT_STRATEGY
#
# Examples:
#RESEARCHER_QUICK_SEARCH_REACT_STRATEGY=fast
#RESEARCHER_DEEP_ANALYSIS_REACT_STRATEGY=deep
#WRITER_TECHNICAL_REACT_STRATEGY=balanced
#WRITER_CREATIVE_REACT_STRATEGY=creative

# ============================================================================
# REACT SELF-REFLECTION (FASE 3)
# ============================================================================

# Global Reflection Settings
# Master switch - must be enabled to use reflection
REACT_ENABLE_REFLECTION=false

# Quality threshold for accepting responses (0.0-1.0)
# Responses with score >= threshold are accepted without refinement
# Lower threshold = more lenient, fewer refinements
# Higher threshold = stricter quality control, more refinements
REACT_REFLECTION_QUALITY_THRESHOLD=0.7

# Maximum refinement iterations before accepting response
# Prevents infinite refinement loops
REACT_REFLECTION_MAX_ITERATIONS=2

# Per-Agent Reflection Configuration
# Enable/disable reflection for individual agents
# Note: REACT_ENABLE_REFLECTION must be true for these to work

# Researcher: Reflection for research quality
# Checks for: source quality, depth, recency, coverage, factual accuracy
RESEARCHER_ENABLE_REFLECTION=false
RESEARCHER_REFLECTION_THRESHOLD=0.7
RESEARCHER_REFLECTION_MAX_ITERATIONS=2

# Analyst: Reflection for analytical rigor
# Checks for: logic, evidence, depth, clarity, actionability
ANALYST_ENABLE_REFLECTION=false
ANALYST_REFLECTION_THRESHOLD=0.75
ANALYST_REFLECTION_MAX_ITERATIONS=2

# Writer: Reflection for content quality
# Checks for: engagement, structure, tone, completeness, grammar
# Higher threshold for content quality assurance
WRITER_ENABLE_REFLECTION=false
WRITER_REFLECTION_THRESHOLD=0.8
WRITER_REFLECTION_MAX_ITERATIONS=3

# Supervisor: Usually disabled (fast coordination)
# Lower threshold for quick decisions
SUPERVISOR_ENABLE_REFLECTION=false
SUPERVISOR_REFLECTION_THRESHOLD=0.6
SUPERVISOR_REFLECTION_MAX_ITERATIONS=1

# ============================================================================
# REACT STRUCTURED LOGGING (FASE 4)
# ============================================================================

# Enable structured logging of ReAct execution
# Provides detailed event tracking, metrics, and execution history
REACT_ENABLE_STRUCTURED_LOGGING=false

# Log output format
# Options: json, human, both
# - json: Machine-readable JSON format for analysis
# - human: Human-readable format for debugging
# - both: Output both formats
REACT_LOG_FORMAT=human

# Save logs to file
# If true, logs are saved to logs/react/{agent_name}/{task_id}.json
REACT_SAVE_LOGS=false

# Log retention in days (0 = keep forever)
REACT_LOG_RETENTION_DAYS=30

# Include full message content in logs
# Warning: May contain sensitive data, disable in production if needed
REACT_LOG_INCLUDE_CONTENT=true

# Event types to log (comma-separated)
# Options: thought, action, observation, reflection, refinement, completion, error
# Default: all events
REACT_LOG_EVENTS=thought,action,observation,reflection,refinement,completion,error

# ============================================================================
# REACT ADVANCED REASONING MODES (FASE 6)
# ============================================================================

# Chain-of-Thought (CoT) Explicit Reasoning
REACT_COT_ENABLED=false
REACT_COT_MIN_STEPS=2
REACT_COT_LOG_STEPS=true
REACT_COT_REQUIRE_CONFIDENCE=true

# Tree-of-Thought (ToT) Multi-Path Exploration
REACT_TOT_ENABLED=false
REACT_TOT_MAX_BRANCHES=5
REACT_TOT_MAX_DEPTH=4
REACT_TOT_EVALUATION_THRESHOLD=0.6

# Adaptive Reasoning (Dynamic Strategy Switching)
REACT_ADAPTIVE_ENABLED=false
REACT_ADAPTIVE_MAX_ESCALATIONS=3
REACT_ADAPTIVE_ESCALATION_THRESHOLD=0.3
REACT_ADAPTIVE_COMPLEXITY_DETECTION=true

# Per-Agent Advanced Mode Preferences
# Options: "cot_explicit", "tree_of_thought", "adaptive", "none"
SUPERVISOR_ADVANCED_MODE=none
RESEARCHER_ADVANCED_MODE=cot_explicit
ANALYST_ADVANCED_MODE=tree_of_thought
WRITER_ADVANCED_MODE=adaptive

# Tool Configuration
TAVILY_API_KEY=""
REDDIT_CLIENT_ID=""
REDDIT_CLIENT_SECRET=""

# Agent Management
# Comma-separated list of agents to enable
# Options: researcher, analyst, writer
# Example: ENABLED_AGENTS=researcher,writer (disables analyst)
ENABLED_AGENTS=researcher,analyst,writer

# Number of retry attempts when agent is unavailable
AGENT_RETRY_ATTEMPTS=3

# Health check interval in seconds for monitoring agent availability
AGENT_HEALTH_CHECK_INTERVAL=30

# ============================================================================
# MCP SERVERS INTEGRATION
# ============================================================================

# Master switch for MCP integration
# Set to true to enable external MCP servers and tools
MCP_ENABLE=false

# MCP Client Configuration
MCP_CLIENT_RETRY_ATTEMPTS=3
MCP_CLIENT_TIMEOUT=30.0
MCP_HEALTH_CHECK_INTERVAL=60.0

# MCP Tools in ReAct Pattern
# Control how MCP tools are integrated into the ReAct reasoning cycle
MCP_TOOLS_ENABLE_LOGGING=true
MCP_TOOLS_ENABLE_REFLECTION=false
MCP_TOOLS_TIMEOUT_MULTIPLIER=1.5

# Supervisor as MCP Server
# Expose the Supervisor agent as an MCP server for external consumption
SUPERVISOR_MCP_ENABLE=false
SUPERVISOR_MCP_PATH=/mcp
SUPERVISOR_MCP_TRANSPORT=streamable_http

# ============================================================================
# EXAMPLE MCP SERVER CONFIGURATIONS
# ============================================================================

# Example 1: Remote MCP Server with Streamable HTTP (Recommended)
# Uncomment and configure to add a remote MCP server
#MCP_SERVER_CORPORATE_TYPE=remote
#MCP_SERVER_CORPORATE_TRANSPORT=streamable_http
#MCP_SERVER_CORPORATE_URL=http://localhost:8001/mcp
#MCP_SERVER_CORPORATE_API_KEY=your_api_key_here
#MCP_SERVER_CORPORATE_ENABLED=true
#MCP_SERVER_CORPORATE_TIMEOUT=30.0

# Example 2: Remote MCP Server with SSE (Legacy)
#MCP_SERVER_LEGACY_TYPE=remote
#MCP_SERVER_LEGACY_TRANSPORT=sse
#MCP_SERVER_LEGACY_URL=http://localhost:8002
#MCP_SERVER_LEGACY_ENABLED=true

# Example 3: Local MCP Server from Python File
# Loads a local FastMCP server implementation
#MCP_SERVER_LOCAL_TOOLS_TYPE=local
#MCP_SERVER_LOCAL_TOOLS_TRANSPORT=stdio
#MCP_SERVER_LOCAL_TOOLS_LOCAL_PATH=/path/to/your/mcp_server.py
#MCP_SERVER_LOCAL_TOOLS_MODULE_NAME=my_mcp_server
#MCP_SERVER_LOCAL_TOOLS_ENABLED=true

# Example 4: Corporate Database Query Server
# Using the corporate_server example from this repo
#MCP_SERVER_CORPORATE_TYPE=remote
#MCP_SERVER_CORPORATE_TRANSPORT=streamable_http
#MCP_SERVER_CORPORATE_URL=http://localhost:8001
#MCP_SERVER_CORPORATE_ENABLED=true

# ============================================================================
# MCP SERVER CONFIGURATION REFERENCE
# ============================================================================
#
# For each MCP server, define configuration using this pattern:
# MCP_SERVER_{NAME}_{PARAM}={VALUE}
#
# Available parameters:
#
# TYPE (required): "remote" or "local"
#   - remote: External MCP server accessed via HTTP
#   - local: Local Python module with FastMCP implementation
#
# TRANSPORT (required): "streamable_http", "sse", or "stdio"
#   - streamable_http: Modern HTTP streaming (recommended for remote)
#   - sse: Server-Sent Events (legacy, for remote)
#   - stdio: Standard I/O (for local only)
#
# For REMOTE servers:
#   URL (required): Full URL to the MCP server endpoint
#   API_KEY (optional): Bearer token for authentication
#   HEADERS (optional): Additional HTTP headers (JSON format)
#
# For LOCAL servers:
#   LOCAL_PATH (required): Absolute path to Python file
#   MODULE_NAME (optional): Custom module name for import
#
# Common parameters:
#   ENABLED (optional, default=true): Enable/disable this server
#   TIMEOUT (optional, default=30.0): Request timeout in seconds
#
# ============================================================================
